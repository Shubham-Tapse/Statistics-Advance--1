{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3df360a5-bf00-40a7-aa1c-6827897df631",
   "metadata": {},
   "source": [
    "                                        Statistics Advance -1 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44581068-568f-410d-b9b0-0dda86502089",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72aaa7aa-54c8-4d8e-8d13-cf0045be3176",
   "metadata": {},
   "source": [
    "Q1. Explain the properties of the F-distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d20c78-62ff-4c75-be88-ada1fca0352b",
   "metadata": {},
   "source": [
    "Ans. The F-distribution has these key properties:\n",
    "\n",
    "1. Non-Negative and Right-Skewed: Takes only positive values and is right-skewed with a long tail.\n",
    "\n",
    "2. Degrees of Freedom: Shaped by the degrees of freedom of the variances in the numerator and denominator.\n",
    "\n",
    "3. Uses in Hypothesis Testing: Commonly applied in ANOVA and regression for comparing variances, with critical values used to assess the significance of the F-statistic.\n",
    "\n",
    "4. Derived from Variance Ratios: It is the ratio of two independent sample variances.\n",
    "\n",
    "5. Right Tail Test: Hypothesis tests using the F-distribution are generally right-tailed, as the distribution is skewed to the right.\n",
    "\n",
    "6. As Degrees of Freedom Increase: As the degrees of freedom increase, the F-distribution becomes less skewed and approaches a normal distribution.\n",
    "\n",
    "7. No Symmetry: Unlike the normal distribution, the F-distribution is asymmetric.\n",
    "\n",
    "8. Depends on Sample Size: The shape of the distribution changes with the sample sizes of the groups being compared.\n",
    "\n",
    "9. Strictly Positive Mode: The mode (peak) of the F-distribution is strictly positive and shifts depending on the degrees of freedom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4ef748-80b6-461b-b185-01d935ac3b11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb4c0dff-d362-47f1-81ba-0e1bdbd8c775",
   "metadata": {},
   "source": [
    "Q2. In which types of statistical tests is the F-distribution used, and why is it appropriate for these tests ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4e1a70-b63f-4561-a9ae-3e3545e9930f",
   "metadata": {},
   "source": [
    "Ans. The F-distribution is used in the following statistical tests:\n",
    "\n",
    "1. ANOVA: Compares the variance between groups and within groups to test if group means are different. The F-distribution is ideal for comparing variances.\n",
    "\n",
    "2. Regression Analysis: Tests the overall significance of a regression model by comparing explained to unexplained variance.\n",
    "    \n",
    "3. F-Test for Equality of Variances: Compares two sample variances to determine if they come from populations with equal variances.\n",
    "    \n",
    "4. Two-Way ANOVA: Analyzes interaction effects between two variables on a dependent variable.\n",
    "\n",
    "5. Testing Multiple Linear Restrictions: In regression, compares restricted and unrestricted models to test if additional parameters improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863bccdf-07bc-422d-be1e-7b6b93ad1826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4c77eb1-bfa0-431b-9a86-52eee62dd367",
   "metadata": {},
   "source": [
    "Q3. What are the key assumptions required for conducting an F-test to compare the variances of two\n",
    "populations ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa83f9b3-946a-48a6-bcdc-f85a9c6873cb",
   "metadata": {},
   "source": [
    "Ans. The key assumptions required for conducting an F-test to compare the variances of two populations are:\n",
    "\n",
    "1. Independence of Samples: The two samples being compared must be independent of each other. The outcome or variance in one sample should not influence the other.\n",
    "\n",
    "2. Normality of Populations: Both populations from which the samples are drawn should be normally distributed. The F-test is sensitive to deviations from normality, especially with small sample sizes.\n",
    "\n",
    "3. Random Sampling: The samples should be randomly selected from their respective populations to ensure that the results are unbiased and representative.\n",
    "\n",
    "4. Ratio of Variances: The F-test compares the ratio of variances. Both populations should have finite, non-zero variances, as the test evaluates whether the two variances are equal.\n",
    "\n",
    "5. Homoscedasticity (for ANOVA context): In the context of ANOVA, an additional assumption is that the variances of the different groups being compared should be roughly equal, although this assumption is relaxed for the F-test specifically comparing two variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0202952-41eb-4798-9204-1b513eef908c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54813671-ce90-488b-85b4-431522ad859d",
   "metadata": {},
   "source": [
    "Q4. What is the purpose of ANOVA, and how does it differ from a t-test ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfdc9dc-cf32-476d-b1f8-cf8811b6d9fb",
   "metadata": {},
   "source": [
    "Ans. Purpose of ANOVA: ANOVA (Analysis of Variance) compares the means of three or more groups to determine if there are significant differences by analyzing variance between and within groups.\n",
    "\n",
    "Purpose of a t-test: A t-test compares the means of two groups to test if the difference between them is statistically significant.\n",
    "\n",
    "Key Differences:\n",
    "\n",
    "1. Number of Groups:\n",
    "\n",
    "ANOVA: Compares 3 or more groups.\n",
    "\n",
    "t-test: Compares 2 groups.\n",
    "\n",
    "2. Variance Assessed:\n",
    "\n",
    "ANOVA: Examines between- and within-group variance.\n",
    "\n",
    "t-test: Focuses on the mean difference.\n",
    "\n",
    "3. Type I Error:\n",
    "\n",
    "ANOVA: Controls Type I error for multiple comparisons.\n",
    "\n",
    "t-test: Higher risk of Type I error when comparing multiple pairs.\n",
    "\n",
    "4. Post-hoc Testing:\n",
    "\n",
    "ANOVA: Requires post-hoc tests to find specific group differences.\n",
    "\n",
    "t-test: Directly compares two groups without post-hoc tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296112d8-0682-4189-8799-12a5f4ee1220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "397ceade-4954-43ab-92b6-3ae987387c06",
   "metadata": {},
   "source": [
    "Q5. Explain when and why you would use a one-way ANOVA instead of multiple t-tests when comparing more\n",
    "than two groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3e5651-a18f-4782-bb30-23e047117814",
   "metadata": {},
   "source": [
    "Ans. When to Use One-Way ANOVA Instead of Multiple t-tests: Use one-way ANOVA when comparing the means of three or more groups.\n",
    "\n",
    "Reasons:\n",
    "\n",
    "1. Control of Type I Error Rate: Reduces the risk of false positives that accumulate with multiple t-tests.\n",
    "\n",
    "2. Single Hypothesis Test: Tests one hypothesis about the equality of means across all groups, simplifying analysis.\n",
    "\n",
    "3. Efficiency: Conducts one analysis instead of multiple tests, reducing computational load.\n",
    "\n",
    "4. Handling Variance: Compares both between-group and within-group variability, providing a comprehensive analysis.\n",
    "\n",
    "5. Post-hoc Analysis: Allows for systematic post-hoc testing to identify specific group differences if significant results are found.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d6ea12-c858-4553-8a56-93d74a70c95c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bb12639-46f7-4e29-a0c8-f903f8f8a7fe",
   "metadata": {},
   "source": [
    "Q6. Explain how variance is partitioned in ANOVA into between-group variance and within-group variance.\n",
    "How does this partitioning contribute to the calculation of the F-statistic?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29650dc0-d084-49a3-ab0c-2e4770fda5b5",
   "metadata": {},
   "source": [
    "Ans. In ANOVA (Analysis of Variance), variance is partitioned into two components:\n",
    "\n",
    "1. Between-Group Variance: This measures how much the group means differ from the overall mean. It reflects the variability due to the differences between the groups being compared.\n",
    "\n",
    "2. Within-Group Variance: This measures the variability of individual observations within each group around their respective group mean. It indicates how much variation exists within each group.\n",
    "\n",
    "3. Contribution to the F-statistic: The F-statistic is calculated by comparing the between-group variance to the within-group variance.\n",
    "\n",
    "4. A higher F-statistic suggests that the variability between group means is greater than the variability within groups, indicating that at least one group mean is significantly different from the others. This helps determine whether the differences observed among the groups are statistically significant.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b766804-e7be-49bd-a547-d653edaaa068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67e95923-0e5f-4023-a8f4-e4ca11043f8c",
   "metadata": {},
   "source": [
    "Q7. Compare the classical (frequentist) approach to ANOVA with the Bayesian approach. What are the key\n",
    "differences in terms of how they handle uncertainty, parameter estimation, and hypothesis testing?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ed320e-2f9b-4c9d-bbee-6882cc45b16d",
   "metadata": {},
   "source": [
    "Ans. Comparison of Classical (Frequentist) and Bayesian Approaches to ANOVA:\n",
    "\n",
    "1. Handling Uncertainty:\n",
    "   \n",
    "Frequentist: Uses confidence intervals and p-values to quantify uncertainty, focusing on long-run frequencies.\n",
    "\n",
    "Bayesian: Expresses uncertainty with probability distributions, incorporating prior knowledge and updating beliefs with observed data.\n",
    "\n",
    "2. Parameter Estimation:\n",
    "\n",
    "Frequentist: Estimates parameters using point estimates (e.g., sample means) and treats them as fixed but unknown.\n",
    "\n",
    "Bayesian: Treats parameters as random variables with probability distributions, providing estimates from the posterior distribution.\n",
    "\n",
    "\n",
    "3. Hypothesis Testing:\n",
    "\n",
    "Frequentist: Employs null hypothesis significance testing (NHST) with fixed thresholds (e.g., alpha = 0.05) to determine if to reject the null hypothesis.\n",
    "\n",
    "Bayesian: Uses Bayes factors or posterior probabilities to compare the strength of evidence for different hypotheses.\n",
    "\n",
    "4. Summary:\n",
    "   \n",
    "The frequentist approach focuses on long-term properties and fixed estimates, while the Bayesian approach incorporates prior knowledge and provides a more flexible interpretation of uncertainty and hypothesis testing.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ae6395-6055-473e-ae73-fce8f0a310a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b065b237-8ec7-4b93-8c0b-e26190c3a4a4",
   "metadata": {},
   "source": [
    "Q8. You have two sets of data representing the incomes of two different professions:\n",
    "\n",
    ". Profession A: [48, 52, 55, 60, 62]\n",
    "\n",
    ". Profession B: [45, 50, 55, 52, 47] Perform an F-test to determine if the variances of the two professions'\n",
    "incomes are equal. What are your conclusions based on the F-test?\n",
    "\n",
    "Task: Use Python to calculate the F-statistic and p-value for the given data.\n",
    "\n",
    "Objective: Gain experience in performing F-tests and interpreting the results in terms of variance comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a54c45f3-54da-430f-9aa5-2d68295ee532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 2.09\n",
      "p-value: 0.247\n",
      "Fail to reject the null hypothesis: variances are equal.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Data for the two professions\n",
    "profession_A = np.array([48, 52, 55, 60, 62])\n",
    "profession_B = np.array([45, 50, 55, 52, 47])\n",
    "\n",
    "# Calculate the variances of the two professions\n",
    "var_A = np.var(profession_A, ddof=1)  # Sample variance\n",
    "var_B = np.var(profession_B, ddof=1)  # Sample variance\n",
    "\n",
    "# Calculate the F-statistic\n",
    "F_statistic = var_A / var_B\n",
    "\n",
    "# Degrees of freedom\n",
    "df_A = len(profession_A) - 1\n",
    "df_B = len(profession_B) - 1\n",
    "\n",
    "# Calculate the p-value for the F-test\n",
    "p_value = stats.f.sf(F_statistic, df_A, df_B)  # Right tail\n",
    "\n",
    "# Print results\n",
    "print(f\"F-statistic: {F_statistic:.2f}\")\n",
    "print(f\"p-value: {p_value:.3f}\")\n",
    "\n",
    "# Conclusion\n",
    "alpha = 0.05\n",
    "if p_value > alpha:\n",
    "    print(\"Fail to reject the null hypothesis: variances are equal.\")\n",
    "else:\n",
    "    print(\"Reject the null hypothesis: variances are not equal.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3dade8-ebf2-4b5e-a30a-0194e975c392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbe2873e-b021-40a7-b913-8d45d2331536",
   "metadata": {},
   "source": [
    "Q9. Conduct a one-way ANOVA to test whether there are any statistically significant differences in average heights between three different regions with the following data:\n",
    "\n",
    ". Region A: [160, 162, 165, 158, 164]\n",
    "\n",
    ". Region B: [172, 175, 170, 168, 174]\n",
    "\n",
    ". Region C: [180, 182, 179, 185, 183]\n",
    "\n",
    ". Task: Write Python code to perform the one-way ANOVA and interpret the results.\n",
    "\n",
    ". Objective: Learn how to perform one-way ANOVA using Python and interpret F-statistic and p-value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21a1f678-0b76-4263-bf4a-212c0753e875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 67.87\n",
      "p-value: 2.870664e-07\n",
      "Reject the null hypothesis: there are significant differences in average heights among the regions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Data for the three regions\n",
    "region_A = np.array([160, 162, 165, 158, 164])\n",
    "region_B = np.array([172, 175, 170, 168, 174])\n",
    "region_C = np.array([180, 182, 179, 185, 183])\n",
    "\n",
    "# Combine the data into a single array for ANOVA\n",
    "data = [region_A, region_B, region_C]\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "F_statistic, p_value = stats.f_oneway(*data)\n",
    "\n",
    "# Print results\n",
    "print(f\"F-statistic: {F_statistic:.2f}\")\n",
    "print(f\"p-value: {p_value:.6e}\")\n",
    "\n",
    "# Conclusion\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: there are significant differences in average heights among the regions.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: no significant differences in average heights among the regions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb12240-01ed-4ead-a1a4-7e464f44e19f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df868213-e4df-43ef-82a6-4a115f4c7889",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
